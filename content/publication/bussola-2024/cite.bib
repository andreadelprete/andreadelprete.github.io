@inproceedings{Bussola2024,
 abstract = {In this work, we consider the complex control problem of making a monopod reach a target with a jump. The monopod can jump in any direction and the terrain underneath its foot can be uneven. This is a template of a much larger class of problems, which are extremely challenging and computationally expensive to solve using standard optimisation-based techniques. Reinforcement Learning (RL) could be an interesting alternative, but the application of an end-to-end approach in which the controller must learn everything from scratch, is impractical. The solution advocated in this paper is to guide the learning process within an RL framework by injecting physical knowledge. This expedient brings to widespread benefits, such as a drastic reduction of the learning time, and the ability to learn and compensate for possible errors in the low-level controller executing the motion. We demonstrate the advantage of our approach with respect to both optimization-based and end-to-end RL approaches.},
 archiveprefix = {arXiv},
 arxivid = {2309.07038},
 author = {Bussola, Riccardo and Focchi, Michele and Del Prete, Andrea and Fontanelli, Daniele and Palopoli, Luigi},
 booktitle = {CDC (under review)},
 eprint = {2309.07038},
 file = {:Users/adelprete/Documents/Mendeley Desktop/Bussola et al/2024/Bussola et al. - 2024 - Efficient Reinforcement Learning for Jumping Monopods.pdf:pdf},
 title = {Efficient Reinforcement Learning for Jumping Monopods},
 url = {http://arxiv.org/abs/2309.07038},
 year = {2024}
}
